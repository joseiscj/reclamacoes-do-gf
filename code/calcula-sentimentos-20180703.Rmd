---
title: "Analisa sentimentos das reclamacoes"
output:
  html_document:
    df_print: paged
---

```{r warning=FALSE}
library(tidyverse)
library(tidytext)
library(here)
library(lexiconPT)
theme_set(theme_bw())
```

```{r carrega}
reclamacoes = read_csv(here("data/3-avaliacao-humana/reclamacoes-avaliadas-20181113.csv"))

#reclamacoes = reclamacoes_raw %>% 
#    mutate(
#        nome_orgao_site = orgao,
#        orgao = str_split(link, "/") %>% map_chr(~ .[[5]])
#    ) %>% 
#    filter(orgao %in% c("inss-ministerio-da-previdencia-social", #"anac-agencia-nacional-de-aviacao-civil")) %>% 
#    mutate(id = 1:n(), 
#           grupo_avaliando = id %% 6 + 1) 
```

O processo de estimativa sera muito baseado em https://sillasgonzaga.github.io/2017-09-23-sensacionalista-pt01/ . 

```{r prepara_sentimento}
data("oplexicon_v3.0")
data("sentiLex_lem_PT02")

op30 <- oplexicon_v3.0
sent <- sentiLex_lem_PT02

glimpse(op30)
```

Precisamos de um dataframe onde cada observacao eh uma palavra. 

```{r separa}
palavra_a_palavra = reclamacoes %>% 
    select(id, reclamacao) %>% 
    unnest_tokens(termo, reclamacao)

palavra_a_palavra %>%
  select(id, termo) %>%
  head(20)

palavras_com_sentimento = palavra_a_palavra %>% 
  left_join(op30 %>% select(term, op30 = polarity), by = c("termo" = "term")) %>% 
  left_join(sent %>% select(term, sent = polarity), by = c("termo" = "term")) 
```

Agora, de fato, calculamos qual a polaridade acumulada (via somatorio) de cada reclamacao e salvamos em um csv.

Abaixo, calculamos a polaridade invertida das variáveis "sentimento_op30" e "sentimento_sent". Os valores de cada elemento dos léxicos têm seu valor mudado, porquê a relação da polaridade invertida faz mais sentido ao nosso escopo pois quanto maior a polaridade invertida, mais insatisfeito está a pessoa com aquela reclamação. O valor das polaridades invertidas é guardado nas novas colunas "sentimento_op30_inv" e "sentimento_sent_inv".
Além disso, normalizamos as polaridades invertidas dos léxicos no intervalo [1,5] e, posteriormente, analisamos a qualidade do léxico usando o desvio quadrático médio do mesmo com a avaliação humana. 

```{r calcula_sentimentos}
sentimentos = palavras_com_sentimento %>% 
    group_by(id) %>%
    summarise(sentimento_op30 = sum(op30, na.rm = TRUE),
              palavras_op30 = sum(!is.na(op30)),
              sentimento_sent = sum(sent, na.rm = TRUE), 
              palavras_sent = sum(!is.na(sent)), 
              palavras = n())

sentimentos["sentimento_op30_inv"] <- -sentimentos["sentimento_op30"]
sentimentos["sentimento_sent_inv"] <- -sentimentos["sentimento_sent"]
normalizacao <- function(p, pi) {
    round(pi- min(p))/((abs(max(p) - min(p)) / 4 ) + 1 )
}

sentimentos["sentimento_op30_norm"] <- apply(sentimentos["sentimento_op30_inv"], 1, function(pi) normalizacao(sentimentos["sentimento_op30_inv"], pi))

sentimentos["sentimento_sent_norm"] <- apply(sentimentos["sentimento_sent_inv"], 1, function(pi) normalizacao(sentimentos["sentimento_sent_inv"], pi))

rmse <- function(m, o) {
    sqrt(mean((m-o)^2))
}

a <- rmse(sentimentos["sentimento_op30_norm"], sentimentos["sentimento_op30"])
a

b <- rmse(sentimentos["sentimento_sent_norm"], sentimentos["sentimento_sent"])
b

sentimentos %>% 
    write_csv(here("data/4-estimativa-automatica/sentimento.csv"))
```

